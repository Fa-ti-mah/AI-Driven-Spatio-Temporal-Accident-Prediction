{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8835fc-24b3-4e27-943f-309e500e54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import gc, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c296357-b855-4bbb-aeec-7955e7843a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Rows: 7728394 Columns: 46\n",
      "Columns preview: ['ID', 'Source', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Description', 'Street', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\n"
     ]
    }
   ],
   "source": [
    "# Loading Dataset\n",
    "DATA_FN = \"US_Accidents_March23.parquet\"  # Using Parquet file instead of CSV\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "N_JOBS = -1\n",
    "RANDOM_SEARCH_ITER = 30\n",
    "CV_FOLDS = 5\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_parquet(DATA_FN, engine='pyarrow')\n",
    "print(\"Rows:\", len(df), \"Columns:\", len(df.columns))\n",
    "print(\"Columns preview:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9c04208-f240-439d-ab7c-3b6537c5e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaning complete.\n",
      "Dataset shape after cleaning: (7494396, 38)\n",
      "\n",
      "Top missing columns:\n",
      " Start_Time           9.53399\n",
      "Source               0.00000\n",
      "Station              0.00000\n",
      "Bump                 0.00000\n",
      "Crossing             0.00000\n",
      "Give_Way             0.00000\n",
      "Junction             0.00000\n",
      "No_Exit              0.00000\n",
      "Railway              0.00000\n",
      "Roundabout           0.00000\n",
      "Stop                 0.00000\n",
      "Weather_Condition    0.00000\n",
      "Traffic_Calming      0.00000\n",
      "Traffic_Signal       0.00000\n",
      "Turning_Loop         0.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DATA CLEANING & PREPARATION PIPELINE\n",
    "\n",
    "import gc, os\n",
    "\n",
    "# Exclusion list ---\n",
    "EXCLUDE_COLS = [\n",
    "    \"ID\", \"Description\", \"Country\", \"Zipcode\", \n",
    "    \"Street\", \"Airport_Code\", \"City\", \"County\"\n",
    "]\n",
    "\n",
    "# Boolean-like columns ---\n",
    "bool_cols = [\n",
    "    \"Amenity\", \"Bump\", \"Crossing\", \"Give_Way\", \"Junction\", \n",
    "    \"No_Exit\", \"Railway\", \"Roundabout\", \"Station\", \"Stop\", \n",
    "    \"Traffic_Calming\", \"Traffic_Signal\", \"Turning_Loop\"\n",
    "]\n",
    "\n",
    "#  Convert boolean-like columns to True/False ---\n",
    "for col in bool_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(bool)\n",
    "\n",
    "# Handle datetime columns ---\n",
    "for c in [\"Start_Time\", \"End_Time\", \"Weather_Timestamp\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors='coerce')\n",
    "\n",
    "# -Fill missing numeric columns with median ---\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "#  Fill missing categorical columns with 'Unknown' ---\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# --- Fill missing datetime columns with median of Start_Time ---\n",
    "for c in [\"End_Time\", \"Weather_Timestamp\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna(df[\"Start_Time\"].median())\n",
    "\n",
    "# --- Drop duplicates based on unique ID ---\n",
    "if \"ID\" in df.columns:\n",
    "    df = df.drop_duplicates(subset=[\"ID\"], keep=\"first\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# -Drop excluded columns if they exist -\n",
    "df = df.drop(columns=[col for col in EXCLUDE_COLS if col in df.columns], errors='ignore')\n",
    "\n",
    "# Drop rows where any categorical feature == 'Unknown' ---\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "df = df[~df[cat_cols].isin(['Unknown']).any(axis=1)]\n",
    "\n",
    "print(\"✅ Cleaning complete.\")\n",
    "print(f\"Dataset shape after cleaning: {df.shape}\")\n",
    "\n",
    "# --- Missingness Analysis ---\n",
    "OUTPUT_DIR = \"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "missing_pct = df.isna().mean().sort_values(ascending=False) * 100\n",
    "missing_pct.to_csv(os.path.join(OUTPUT_DIR, \"missingness_percent.csv\"))\n",
    "print(\"\\nTop missing columns:\\n\", missing_pct.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a440faa-5b5e-4fb8-b427-443ebad2dbd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 686. MiB for an array with shape (12, 7494396) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m TARGET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeverity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# --- Separate features and target ---\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[TARGET])\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m df[TARGET]\n\u001b[0;32m      9\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeverity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4869\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4866\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   4868\u001b[0m bm_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m axis_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 4869\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m   4870\u001b[0m     new_axis,\n\u001b[0;32m   4871\u001b[0m     indexer,\n\u001b[0;32m   4872\u001b[0m     axis\u001b[38;5;241m=\u001b[39mbm_axis,\n\u001b[0;32m   4873\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4874\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4875\u001b[0m     only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m   4876\u001b[0m )\n\u001b[0;32m   4877\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_mgr, axes\u001b[38;5;241m=\u001b[39mnew_mgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   4878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:843\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[0;32m    841\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    842\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 843\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mtake_nd(taker, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, new_mgr_locs\u001b[38;5;241m=\u001b[39mmgr_locs)\n\u001b[0;32m    844\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m   1308\u001b[0m     values, indexer, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m   1309\u001b[0m )\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 686. MiB for an array with shape (12, 7494396) and data type float64"
     ]
    }
   ],
   "source": [
    "# LASSO REGULARIZATION MODELING + FEATURE IMPORTANCE PLOT\n",
    "\n",
    "TARGET = \"Severity\"\n",
    "\n",
    "# --- Separate features and target ---\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "target = \"Severity\"\n",
    "EXCLUDE_COLS = [\n",
    "    \"ID\", \"Description\", \"Country\", \"Zipcode\",\n",
    "    \"Street\", \"Airport_Code\", \"City\", \"County\"\n",
    "]\n",
    "\n",
    "# Drop excluded columns\n",
    "df_model = df.drop(columns=[c for c in EXCLUDE_COLS if c in df.columns])\n",
    "\n",
    "# Drop rows with \"Unknown\" categories\n",
    "cat_cols = df_model.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    df_model = df_model[df_model[col] != \"Unknown\"]\n",
    "\n",
    "# Separate X and y\n",
    "X = df_model.drop(columns=[target])\n",
    "y = df_model[target].astype(int)\n",
    "\n",
    "# ===================== 2. Split train/test =====================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ===================== 3. Preprocessing pipeline =====================\n",
    "num_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "bool_cols = X.select_dtypes(include=['bool']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
    "        ('bool', 'passthrough', bool_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ===================== 4. Lasso Regularization (Logistic Regression with L1) =====================\n",
    "lasso_clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(\n",
    "        penalty='l1',\n",
    "        solver='liblinear',\n",
    "        C=0.1,        # Regularization strength (smaller = stronger regularization)\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "lasso_clf.fit(X_train, y_train)\n",
    "\n",
    "# ===================== 5. Evaluate =====================\n",
    "y_pred = lasso_clf.predict(X_test)\n",
    "\n",
    "print(\"✅ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n✅ Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ===================== 6. Get feature importance =====================\n",
    "# Extract feature names from one-hot and numeric\n",
    "feature_names = (\n",
    "    list(num_cols) +\n",
    "    list(lasso_clf.named_steps['preprocessor']\n",
    "         .named_transformers_['cat']\n",
    "         .get_feature_names_out(cat_cols)) +\n",
    "    list(bool_cols)\n",
    ")\n",
    "\n",
    "coefficients = lasso_clf.named_steps['classifier'].coef_[0]\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "importance_df[\"Abs_Coefficient\"] = importance_df[\"Coefficient\"].abs()\n",
    "importance_df = importance_df.sort_values(\"Abs_Coefficient\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 most influential features (LASSO):\")\n",
    "print(importance_df.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223e55a-04e5-409f-8793-0ba04c57b5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
